{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "05c4cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b954c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9a1749",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413f01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31cb7275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Adapting--Knowledge-Driven-Dialogues-b9edcdbf672eb304\n",
      "Reusing dataset csv (C:\\Users\\14840\\.cache\\huggingface\\datasets\\csv\\Adapting--Knowledge-Driven-Dialogues-b9edcdbf672eb304\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6460cf20070a4e679d6d5409eeafeb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['chat_history', 'last_usr_uttr', 'entity', 'attrs', 'knowledge', 'knowledge_index', 'response'],\n",
       "        num_rows: 25277\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['chat_history', 'last_usr_uttr', 'entity', 'attrs', 'knowledge', 'knowledge_index', 'response'],\n",
       "        num_rows: 6563\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"Adapting/Knowledge-Driven-Dialogues\")\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26858614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "\n",
    "# def preprocess(chat_history):\n",
    "#     chat_history_list = ast.literal_eval(chat_history)\n",
    "#     return ' '.join(chat_history_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4d7974ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knowledge_index</th>\n",
       "      <th>chat_history_concat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25272</th>\n",
       "      <td>37338</td>\n",
       "      <td>你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25273</th>\n",
       "      <td>36573</td>\n",
       "      <td>你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25274</th>\n",
       "      <td>36573</td>\n",
       "      <td>你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25275</th>\n",
       "      <td>36573</td>\n",
       "      <td>你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25276</th>\n",
       "      <td>36573</td>\n",
       "      <td>你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       knowledge_index                                chat_history_concat\n",
       "0                21928                          你知道关于形容文雅有礼貌的样子，这个含义的成语吗？\n",
       "1                21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...\n",
       "2                21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...\n",
       "3                21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...\n",
       "4                21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...\n",
       "...                ...                                                ...\n",
       "25272            37338  你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...\n",
       "25273            36573  你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...\n",
       "25274            36573  你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...\n",
       "25275            36573  你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...\n",
       "25276            36573  你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...\n",
       "\n",
       "[25277 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train = pd.DataFrame(dataset['train'])\n",
    "# df_train = df_train[['chat_history', 'knowledge_index']]\n",
    "\n",
    "# df_train['chat_history_concat'] = df_train['chat_history'].progress_map(preprocess)\n",
    "# df_train.drop(['chat_history'], 1, inplace=True)\n",
    "# # replace NaN index with nearest not null index\n",
    "# last_knowledge_index = -1\n",
    "# for row in df_train.itertuples():\n",
    "#     if pd.isnull(df_train['knowledge_index'][row.Index]):\n",
    "#         if last_knowledge_index == -1: # the first one, doesn't have last index, set it as default (0)\n",
    "#             df_train['knowledge_index'][row.Index] = 0\n",
    "#         else:\n",
    "#             df_train['knowledge_index'][row.Index] = last_knowledge_index\n",
    "#     last_knowledge_index = df_train['knowledge_index'][row.Index]\n",
    "\n",
    "# df_train = df_train.astype({'knowledge_index': 'int32'})\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af25e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 6563/6563 [00:00<00:00, 29850.80it/s]\n",
      "C:\\Users\\14840\\AppData\\Local\\Temp\\ipykernel_15944\\2599325099.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_val.drop(['chat_history'], 1, inplace=True)\n",
      "C:\\Users\\14840\\AppData\\Local\\Temp\\ipykernel_15944\\2599325099.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val['knowledge_index'][row.Index] = last_knowledge_index\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knowledge_index</th>\n",
       "      <th>chat_history_concat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36902</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36902</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36902</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36902</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36529</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6558</th>\n",
       "      <td>25408</td>\n",
       "      <td>你好，你知道安不忘危这个成语吗呵？ 我了解过安不忘危这个成语，你想了解什么呢。 那你能说下安...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6559</th>\n",
       "      <td>25408</td>\n",
       "      <td>你好，你知道安不忘危这个成语吗呵？ 我了解过安不忘危这个成语，你想了解什么呢。 那你能说下安...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6560</th>\n",
       "      <td>25408</td>\n",
       "      <td>你好，你知道安不忘危这个成语吗呵？ 我了解过安不忘危这个成语，你想了解什么呢。 那你能说下安...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6561</th>\n",
       "      <td>25408</td>\n",
       "      <td>你好，你知道安不忘危这个成语吗呵？ 我了解过安不忘危这个成语，你想了解什么呢。 那你能说下安...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562</th>\n",
       "      <td>25408</td>\n",
       "      <td>你好，你知道安不忘危这个成语吗呵？ 我了解过安不忘危这个成语，你想了解什么呢。 那你能说下安...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6563 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      knowledge_index                                chat_history_concat\n",
       "0               36902                           你好，你知道中国科学院植物研究所北京植物园吗呀？\n",
       "1               36902  你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...\n",
       "2               36902  你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...\n",
       "3               36902  你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...\n",
       "4               36529  你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...\n",
       "...               ...                                                ...\n",
       "6558            25408  你好，你知道安不忘危这个成语吗呵？ 我了解过安不忘危这个成语，你想了解什么呢。 那你能说下安...\n",
       "6559            25408  你好，你知道安不忘危这个成语吗呵？ 我了解过安不忘危这个成语，你想了解什么呢。 那你能说下安...\n",
       "6560            25408  你好，你知道安不忘危这个成语吗呵？ 我了解过安不忘危这个成语，你想了解什么呢。 那你能说下安...\n",
       "6561            25408  你好，你知道安不忘危这个成语吗呵？ 我了解过安不忘危这个成语，你想了解什么呢。 那你能说下安...\n",
       "6562            25408  你好，你知道安不忘危这个成语吗呵？ 我了解过安不忘危这个成语，你想了解什么呢。 那你能说下安...\n",
       "\n",
       "[6563 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_val = pd.DataFrame(dataset['validation'])\n",
    "# df_val = df_val[['chat_history', 'knowledge_index']]\n",
    "\n",
    "# df_val['chat_history_concat'] = df_val['chat_history'].progress_map(preprocess)\n",
    "# df_val.drop(['chat_history'], 1, inplace=True)\n",
    "# # replace NaN index with nearest not null index\n",
    "# last_knowledge_index = -1\n",
    "# for row in df_val.itertuples():\n",
    "#     if pd.isnull(df_val['knowledge_index'][row.Index]):\n",
    "#         if last_knowledge_index == -1: # the first one, doesn't have last index, set it as default (0)\n",
    "#             df_val['knowledge_index'][row.Index] = 0\n",
    "#         else:\n",
    "#             df_val['knowledge_index'][row.Index] = last_knowledge_index\n",
    "#     last_knowledge_index = df_val['knowledge_index'][row.Index]\n",
    "\n",
    "# df_val = df_val.astype({'knowledge_index': 'int32'})\n",
    "# df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba77f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv('train_set.csv', index=False)\n",
    "# df_val.to_csv('val_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68df921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knowledge_index</th>\n",
       "      <th>chat_history_concat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25272</th>\n",
       "      <td>37338</td>\n",
       "      <td>你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25273</th>\n",
       "      <td>36573</td>\n",
       "      <td>你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25274</th>\n",
       "      <td>36573</td>\n",
       "      <td>你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25275</th>\n",
       "      <td>36573</td>\n",
       "      <td>你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25276</th>\n",
       "      <td>36573</td>\n",
       "      <td>你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       knowledge_index                                chat_history_concat\n",
       "0                21928                          你知道关于形容文雅有礼貌的样子，这个含义的成语吗？\n",
       "1                21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...\n",
       "2                21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...\n",
       "3                21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...\n",
       "4                21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...\n",
       "...                ...                                                ...\n",
       "25272            37338  你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...\n",
       "25273            36573  你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...\n",
       "25274            36573  你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...\n",
       "25275            36573  你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...\n",
       "25276            36573  你好，你去过汇通祠吗？ 他坐北朝南。山门1间，石券门，模盘大门两扇。前殿3间，配房东西各3间...\n",
       "\n",
       "[25277 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train_set.csv')\n",
    "df_val = pd.read_csv('data/val_set.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426fcd81",
   "metadata": {},
   "source": [
    "# 2. Load concatenated knowledge graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c3c134c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>knowledge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>调王生</td>\n",
       "      <td>调王生的时间是明朝。调王生的作者是袁凯。调王生的诗句是门外桃花落渐多，一双新燕又来过。寄语城...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>载伎重游王潭马砦岩</td>\n",
       "      <td>载伎重游王潭马砦岩的时间是明朝。载伎重游王潭马砦岩的作者是程嘉燧。载伎重游王潭马砦岩的诗句是...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>观军装十咏·马</td>\n",
       "      <td>观军装十咏·马的时间是明朝。观军装十咏·马的作者是高启。观军装十咏·马的诗句是罗帕覆春风，连...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>菩萨蛮 回文 中州乐府</td>\n",
       "      <td>菩萨蛮 回文 中州乐府的时间是元朝。菩萨蛮 回文 中州乐府的作者是孟宗献。菩萨蛮 回文 中州...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>西江月·往事俄惊如梦</td>\n",
       "      <td>西江月·往事俄惊如梦的时间是元朝。西江月·往事俄惊如梦的作者是钱应庚。西江月·往事俄惊如梦的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38049</th>\n",
       "      <td>贝恩·血蹄</td>\n",
       "      <td>贝恩·血蹄的亲属(先祖)是血蹄长者。贝恩·血蹄的亲属(母亲)是塔玛拉。贝恩·血蹄的亲属(父亲...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38050</th>\n",
       "      <td>怨恨回响</td>\n",
       "      <td>怨恨回响的所在地是七星殿。怨恨回响的种族是煞（元素生物）。怨恨回响的等级是90。怨恨回响的英...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38051</th>\n",
       "      <td>伊芙·费德里克森</td>\n",
       "      <td>伊芙·费德里克森的势力是提瑞斯法议会。伊芙·费德里克森的头衔是提瑞斯法议会的回忆。伊芙·费德...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38052</th>\n",
       "      <td>女伯爵莉亚德琳</td>\n",
       "      <td>女伯爵莉亚德琳的亲属(养女)是萨兰蒂亚。女伯爵莉亚德琳的亲属(导师/养父)是高阶牧师冯德洛尔...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38053</th>\n",
       "      <td>达瓦尔·普瑞斯托</td>\n",
       "      <td>达瓦尔·普瑞斯托的亲属(distant cousin)是Aiden Perenolde。达瓦...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38054 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            entity                                          knowledge\n",
       "0              调王生  调王生的时间是明朝。调王生的作者是袁凯。调王生的诗句是门外桃花落渐多，一双新燕又来过。寄语城...\n",
       "1        载伎重游王潭马砦岩  载伎重游王潭马砦岩的时间是明朝。载伎重游王潭马砦岩的作者是程嘉燧。载伎重游王潭马砦岩的诗句是...\n",
       "2          观军装十咏·马  观军装十咏·马的时间是明朝。观军装十咏·马的作者是高启。观军装十咏·马的诗句是罗帕覆春风，连...\n",
       "3      菩萨蛮 回文 中州乐府  菩萨蛮 回文 中州乐府的时间是元朝。菩萨蛮 回文 中州乐府的作者是孟宗献。菩萨蛮 回文 中州...\n",
       "4       西江月·往事俄惊如梦  西江月·往事俄惊如梦的时间是元朝。西江月·往事俄惊如梦的作者是钱应庚。西江月·往事俄惊如梦的...\n",
       "...            ...                                                ...\n",
       "38049        贝恩·血蹄  贝恩·血蹄的亲属(先祖)是血蹄长者。贝恩·血蹄的亲属(母亲)是塔玛拉。贝恩·血蹄的亲属(父亲...\n",
       "38050         怨恨回响  怨恨回响的所在地是七星殿。怨恨回响的种族是煞（元素生物）。怨恨回响的等级是90。怨恨回响的英...\n",
       "38051     伊芙·费德里克森  伊芙·费德里克森的势力是提瑞斯法议会。伊芙·费德里克森的头衔是提瑞斯法议会的回忆。伊芙·费德...\n",
       "38052      女伯爵莉亚德琳  女伯爵莉亚德琳的亲属(养女)是萨兰蒂亚。女伯爵莉亚德琳的亲属(导师/养父)是高阶牧师冯德洛尔...\n",
       "38053     达瓦尔·普瑞斯托  达瓦尔·普瑞斯托的亲属(distant cousin)是Aiden Perenolde。达瓦...\n",
       "\n",
       "[38054 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_graph = pd.read_csv('knowledge_data_complete.csv')\n",
    "knowledge_graph['knowledge'] = np.where(knowledge_graph['knowledge'].isna(), '', knowledge_graph['knowledge'])\n",
    "knowledge_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a977dcf",
   "metadata": {},
   "source": [
    "Represent knowledge with sentence transformer (dimension=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# sentence_transformer = SentenceTransformer('distiluse-base-multilingual-cased', device=device)\n",
    "# sentence_transformer.max_seq_length = 512\n",
    "# knowledge_embds = sentence_transformer.encode(knowledge_graph['knowledge'].values.tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
    "# torch.save(knowledge_embds, 'knowledge_embds.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41437598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6223e-02,  4.9527e-02,  3.1041e-02,  ..., -2.6152e-03,\n",
       "          1.0002e-02, -6.2648e-04],\n",
       "        [-1.6890e-02,  2.4287e-02, -1.2835e-04,  ...,  1.4184e-02,\n",
       "         -2.1313e-02, -2.8828e-03],\n",
       "        [ 3.3119e-02,  1.2342e-02, -1.5354e-02,  ..., -3.3212e-02,\n",
       "         -1.1755e-02, -5.7809e-03],\n",
       "        ...,\n",
       "        [-1.6554e-02, -3.0252e-02,  3.6206e-02,  ...,  5.9575e-05,\n",
       "          1.1925e-02, -5.8790e-02],\n",
       "        [ 2.6263e-03, -2.6970e-02,  1.4999e-02,  ..., -2.1186e-02,\n",
       "          1.4466e-02, -1.8898e-02],\n",
       "        [-9.0852e-03, -2.0317e-02, -2.6133e-03,  ..., -2.0839e-04,\n",
       "         -4.3073e-02,  1.2080e-02]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knowledge_embds.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c9f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "knowledge_embds = torch.load('knowledge_embds.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd0378",
   "metadata": {},
   "source": [
    "Represent knowledge with Bert chinese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d86c4503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoModel\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')\n",
    "# encoder = AutoModel.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f7aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_knowledge(knowledge_chunk):\n",
    "#     kg_tokenized = tokenizer(knowledge_chunk, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#     kg_outputs = encoder(**kg_tokenized)\n",
    "#     last_hidden_state = kg_outputs[0]\n",
    "#     # print(f'last_hidden_state shape = {last_hidden_state.shape}')\n",
    "#     kg_embds = last_hidden_state[:, 0]\n",
    "#     return kg_embds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f11441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowledge_list = knowledge_graph['knowledge'].values.tolist()\n",
    "# chunk_size = 16\n",
    "# knowledge_embds = [encode_knowledge(knowledge_list[i: min(i+chunk_size, len(knowledge_list))])\n",
    "#                                     for i in range(0, len(knowledge_list), chunk_size)]\n",
    "# knowledge_embds = torch.stack(knowledge_embds, dim=0)\n",
    "# knowledge_embds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8863db5",
   "metadata": {},
   "source": [
    "# 3. Match chat history with existing knowledge to extract entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1915b749",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876b41ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\14840\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopWords = stopwords.words('chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af071002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(corpus):\n",
    "    seg_list = jieba.cut(corpus, cut_all=True)\n",
    "    result = []\n",
    "    for seg in seg_list:\n",
    "        seg = ''.join(seg.split())\n",
    "        if (seg != '' and seg != \"\\n\" and seg != \"\\n\\n\"):\n",
    "            result.append(seg)\n",
    "#     return ' '.join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ee6e02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 38054/38054 [00:24<00:00, 1578.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>knowledge_segs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>调王生</td>\n",
       "      <td>调王生的时间是明朝。调王生的作者是袁凯。调王生的诗句是门外桃花落渐多，一双新燕又来过。寄语城...</td>\n",
       "      <td>[调, 王, 生, 的, 时间, 是, 明朝, 。, 调, 王, 生, 的, 作者, 是, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>载伎重游王潭马砦岩</td>\n",
       "      <td>载伎重游王潭马砦岩的时间是明朝。载伎重游王潭马砦岩的作者是程嘉燧。载伎重游王潭马砦岩的诗句是...</td>\n",
       "      <td>[载, 伎, 重游, 王, 潭, 马, 砦, 岩, 的, 时间, 是, 明朝, 。, 载, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>观军装十咏·马</td>\n",
       "      <td>观军装十咏·马的时间是明朝。观军装十咏·马的作者是高启。观军装十咏·马的诗句是罗帕覆春风，连...</td>\n",
       "      <td>[观, 军装, 十, 咏, ·, 马, 的, 时间, 是, 明朝, 。, 观, 军装, 十,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>菩萨蛮 回文 中州乐府</td>\n",
       "      <td>菩萨蛮 回文 中州乐府的时间是元朝。菩萨蛮 回文 中州乐府的作者是孟宗献。菩萨蛮 回文 中州...</td>\n",
       "      <td>[菩萨, 蛮, 回文, 中州, 乐府, 的, 时间, 是, 元朝, 。, 菩萨, 蛮, 回文...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>西江月·往事俄惊如梦</td>\n",
       "      <td>西江月·往事俄惊如梦的时间是元朝。西江月·往事俄惊如梦的作者是钱应庚。西江月·往事俄惊如梦的...</td>\n",
       "      <td>[西江, 西江月, ·, 往事, 俄, 惊, 如, 梦, 的, 时间, 是, 元朝, 。, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity                                          knowledge  \\\n",
       "0          调王生  调王生的时间是明朝。调王生的作者是袁凯。调王生的诗句是门外桃花落渐多，一双新燕又来过。寄语城...   \n",
       "1    载伎重游王潭马砦岩  载伎重游王潭马砦岩的时间是明朝。载伎重游王潭马砦岩的作者是程嘉燧。载伎重游王潭马砦岩的诗句是...   \n",
       "2      观军装十咏·马  观军装十咏·马的时间是明朝。观军装十咏·马的作者是高启。观军装十咏·马的诗句是罗帕覆春风，连...   \n",
       "3  菩萨蛮 回文 中州乐府  菩萨蛮 回文 中州乐府的时间是元朝。菩萨蛮 回文 中州乐府的作者是孟宗献。菩萨蛮 回文 中州...   \n",
       "4   西江月·往事俄惊如梦  西江月·往事俄惊如梦的时间是元朝。西江月·往事俄惊如梦的作者是钱应庚。西江月·往事俄惊如梦的...   \n",
       "\n",
       "                                      knowledge_segs  \n",
       "0  [调, 王, 生, 的, 时间, 是, 明朝, 。, 调, 王, 生, 的, 作者, 是, ...  \n",
       "1  [载, 伎, 重游, 王, 潭, 马, 砦, 岩, 的, 时间, 是, 明朝, 。, 载, ...  \n",
       "2  [观, 军装, 十, 咏, ·, 马, 的, 时间, 是, 明朝, 。, 观, 军装, 十,...  \n",
       "3  [菩萨, 蛮, 回文, 中州, 乐府, 的, 时间, 是, 元朝, 。, 菩萨, 蛮, 回文...  \n",
       "4  [西江, 西江月, ·, 往事, 俄, 惊, 如, 梦, 的, 时间, 是, 元朝, 。, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_graph['knowledge_segs'] = knowledge_graph['knowledge'].progress_map(segmentation)\n",
    "knowledge_graph.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4e60957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 25277/25277 [00:10<00:00, 2471.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knowledge_index</th>\n",
       "      <th>chat_history_concat</th>\n",
       "      <th>chat_history_segs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？</td>\n",
       "      <td>[你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "      <td>[你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "      <td>[你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "      <td>[你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "      <td>[你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   knowledge_index                                chat_history_concat  \\\n",
       "0            21928                          你知道关于形容文雅有礼貌的样子，这个含义的成语吗？   \n",
       "1            21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...   \n",
       "2            21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...   \n",
       "3            21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...   \n",
       "4            21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...   \n",
       "\n",
       "                                   chat_history_segs  \n",
       "0  [你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...  \n",
       "1  [你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...  \n",
       "2  [你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...  \n",
       "3  [你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...  \n",
       "4  [你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['chat_history_segs'] = df_train['chat_history_concat'].progress_map(segmentation)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fecddf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6563/6563 [00:02<00:00, 2464.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knowledge_index</th>\n",
       "      <th>chat_history_concat</th>\n",
       "      <th>chat_history_segs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36902</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？</td>\n",
       "      <td>[你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36902</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...</td>\n",
       "      <td>[你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36902</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...</td>\n",
       "      <td>[你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36902</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...</td>\n",
       "      <td>[你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36529</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...</td>\n",
       "      <td>[你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   knowledge_index                                chat_history_concat  \\\n",
       "0            36902                           你好，你知道中国科学院植物研究所北京植物园吗呀？   \n",
       "1            36902  你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...   \n",
       "2            36902  你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...   \n",
       "3            36902  你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...   \n",
       "4            36529  你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...   \n",
       "\n",
       "                                   chat_history_segs  \n",
       "0  [你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...  \n",
       "1  [你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...  \n",
       "2  [你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...  \n",
       "3  [你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...  \n",
       "4  [你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['chat_history_segs'] = df_val['chat_history_concat'].progress_map(segmentation)\n",
    "df_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d961ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv_from_text = KeyedVectors.load_word2vec_format('tencent-ailab-embedding-zh-d200-v0.2.0-s.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e18ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vec(segments):\n",
    "    present_segs = [seg for seg in segments if seg in wv_from_text.vocab]\n",
    "    if len(present_segs) > 0:\n",
    "        return sum([np.array(wv_from_text[seg]) for seg in present_segs])/len(present_segs)\n",
    "    else:\n",
    "        return np.zeros(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3277ae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 38054/38054 [00:18<00:00, 2111.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>knowledge_segs</th>\n",
       "      <th>knowledge_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>调王生</td>\n",
       "      <td>调王生的时间是明朝。调王生的作者是袁凯。调王生的诗句是门外桃花落渐多，一双新燕又来过。寄语城...</td>\n",
       "      <td>[调, 王, 生, 的, 时间, 是, 明朝, 。, 调, 王, 生, 的, 作者, 是, ...</td>\n",
       "      <td>[0.098050416, 0.09926371, -0.0010484637, 0.108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>载伎重游王潭马砦岩</td>\n",
       "      <td>载伎重游王潭马砦岩的时间是明朝。载伎重游王潭马砦岩的作者是程嘉燧。载伎重游王潭马砦岩的诗句是...</td>\n",
       "      <td>[载, 伎, 重游, 王, 潭, 马, 砦, 岩, 的, 时间, 是, 明朝, 。, 载, ...</td>\n",
       "      <td>[0.12829532, 0.124212354, -0.002923172, 0.0865...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>观军装十咏·马</td>\n",
       "      <td>观军装十咏·马的时间是明朝。观军装十咏·马的作者是高启。观军装十咏·马的诗句是罗帕覆春风，连...</td>\n",
       "      <td>[观, 军装, 十, 咏, ·, 马, 的, 时间, 是, 明朝, 。, 观, 军装, 十,...</td>\n",
       "      <td>[0.15041035, 0.068896726, -0.024431074, 0.1063...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>菩萨蛮 回文 中州乐府</td>\n",
       "      <td>菩萨蛮 回文 中州乐府的时间是元朝。菩萨蛮 回文 中州乐府的作者是孟宗献。菩萨蛮 回文 中州...</td>\n",
       "      <td>[菩萨, 蛮, 回文, 中州, 乐府, 的, 时间, 是, 元朝, 。, 菩萨, 蛮, 回文...</td>\n",
       "      <td>[0.14912754, 0.1262192, 0.04209491, 0.09762947...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>西江月·往事俄惊如梦</td>\n",
       "      <td>西江月·往事俄惊如梦的时间是元朝。西江月·往事俄惊如梦的作者是钱应庚。西江月·往事俄惊如梦的...</td>\n",
       "      <td>[西江, 西江月, ·, 往事, 俄, 惊, 如, 梦, 的, 时间, 是, 元朝, 。, ...</td>\n",
       "      <td>[0.07052842, 0.120118946, 0.022807427, 0.05465...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity                                          knowledge  \\\n",
       "0          调王生  调王生的时间是明朝。调王生的作者是袁凯。调王生的诗句是门外桃花落渐多，一双新燕又来过。寄语城...   \n",
       "1    载伎重游王潭马砦岩  载伎重游王潭马砦岩的时间是明朝。载伎重游王潭马砦岩的作者是程嘉燧。载伎重游王潭马砦岩的诗句是...   \n",
       "2      观军装十咏·马  观军装十咏·马的时间是明朝。观军装十咏·马的作者是高启。观军装十咏·马的诗句是罗帕覆春风，连...   \n",
       "3  菩萨蛮 回文 中州乐府  菩萨蛮 回文 中州乐府的时间是元朝。菩萨蛮 回文 中州乐府的作者是孟宗献。菩萨蛮 回文 中州...   \n",
       "4   西江月·往事俄惊如梦  西江月·往事俄惊如梦的时间是元朝。西江月·往事俄惊如梦的作者是钱应庚。西江月·往事俄惊如梦的...   \n",
       "\n",
       "                                      knowledge_segs  \\\n",
       "0  [调, 王, 生, 的, 时间, 是, 明朝, 。, 调, 王, 生, 的, 作者, 是, ...   \n",
       "1  [载, 伎, 重游, 王, 潭, 马, 砦, 岩, 的, 时间, 是, 明朝, 。, 载, ...   \n",
       "2  [观, 军装, 十, 咏, ·, 马, 的, 时间, 是, 明朝, 。, 观, 军装, 十,...   \n",
       "3  [菩萨, 蛮, 回文, 中州, 乐府, 的, 时间, 是, 元朝, 。, 菩萨, 蛮, 回文...   \n",
       "4  [西江, 西江月, ·, 往事, 俄, 惊, 如, 梦, 的, 时间, 是, 元朝, 。, ...   \n",
       "\n",
       "                                       knowledge_vec  \n",
       "0  [0.098050416, 0.09926371, -0.0010484637, 0.108...  \n",
       "1  [0.12829532, 0.124212354, -0.002923172, 0.0865...  \n",
       "2  [0.15041035, 0.068896726, -0.024431074, 0.1063...  \n",
       "3  [0.14912754, 0.1262192, 0.04209491, 0.09762947...  \n",
       "4  [0.07052842, 0.120118946, 0.022807427, 0.05465...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_graph['knowledge_vec'] = knowledge_graph['knowledge_segs'].progress_map(sentence_vec)\n",
    "knowledge_graph.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "729c46fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 25277/25277 [00:09<00:00, 2625.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knowledge_index</th>\n",
       "      <th>chat_history_concat</th>\n",
       "      <th>chat_history_segs</th>\n",
       "      <th>chat_history_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？</td>\n",
       "      <td>[你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...</td>\n",
       "      <td>[-0.08105581, 0.16311274, 0.04246238, 0.135791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "      <td>[你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...</td>\n",
       "      <td>[-0.04881819, 0.13854937, 0.004859275, 0.12285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "      <td>[你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...</td>\n",
       "      <td>[0.003928744, 0.15709606, 0.0070967562, 0.1201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "      <td>[你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...</td>\n",
       "      <td>[-7.959275e-07, 0.16947056, 0.015032004, 0.123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21928</td>\n",
       "      <td>你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...</td>\n",
       "      <td>[你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...</td>\n",
       "      <td>[-0.013830395, 0.15001276, 0.011177871, 0.1291...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   knowledge_index                                chat_history_concat  \\\n",
       "0            21928                          你知道关于形容文雅有礼貌的样子，这个含义的成语吗？   \n",
       "1            21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...   \n",
       "2            21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...   \n",
       "3            21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...   \n",
       "4            21928  你知道关于形容文雅有礼貌的样子，这个含义的成语吗？ 彬彬有礼和温文尔雅都有这个意思 我想知道...   \n",
       "\n",
       "                                   chat_history_segs  \\\n",
       "0  [你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...   \n",
       "1  [你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...   \n",
       "2  [你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...   \n",
       "3  [你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...   \n",
       "4  [你, 知道, 关于, 形容, 文雅, 有, 礼貌, 的, 样子, ，, 这个, 含义, 的...   \n",
       "\n",
       "                                    chat_history_vec  \n",
       "0  [-0.08105581, 0.16311274, 0.04246238, 0.135791...  \n",
       "1  [-0.04881819, 0.13854937, 0.004859275, 0.12285...  \n",
       "2  [0.003928744, 0.15709606, 0.0070967562, 0.1201...  \n",
       "3  [-7.959275e-07, 0.16947056, 0.015032004, 0.123...  \n",
       "4  [-0.013830395, 0.15001276, 0.011177871, 0.1291...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['chat_history_vec'] = df_train['chat_history_segs'].progress_map(sentence_vec)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1db1f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6563/6563 [00:02<00:00, 2619.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knowledge_index</th>\n",
       "      <th>chat_history_concat</th>\n",
       "      <th>chat_history_segs</th>\n",
       "      <th>chat_history_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36902</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？</td>\n",
       "      <td>[你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...</td>\n",
       "      <td>[-0.064503215, 0.030785, -0.011886002, 0.04244...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36902</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...</td>\n",
       "      <td>[你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...</td>\n",
       "      <td>[-0.01941134, 0.06088603, 0.030868158, 0.08166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36902</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...</td>\n",
       "      <td>[你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...</td>\n",
       "      <td>[-0.06357059, 0.08505998, 0.014782547, 0.10764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36902</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...</td>\n",
       "      <td>[你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...</td>\n",
       "      <td>[-0.057040103, 0.097636074, 0.01949272, 0.1096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36529</td>\n",
       "      <td>你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...</td>\n",
       "      <td>[你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...</td>\n",
       "      <td>[-0.0597505, 0.10566376, 0.018543258, 0.104555...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   knowledge_index                                chat_history_concat  \\\n",
       "0            36902                           你好，你知道中国科学院植物研究所北京植物园吗呀？   \n",
       "1            36902  你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...   \n",
       "2            36902  你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...   \n",
       "3            36902  你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...   \n",
       "4            36529  你好，你知道中国科学院植物研究所北京植物园吗呀？ 当然知道了，植物园包括树木园、宿根花卉园、...   \n",
       "\n",
       "                                   chat_history_segs  \\\n",
       "0  [你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...   \n",
       "1  [你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...   \n",
       "2  [你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...   \n",
       "3  [你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...   \n",
       "4  [你好, ，, 你, 知道, 中国, 中国科学院, 科学, 科学院, 学院, 植物, 研究,...   \n",
       "\n",
       "                                    chat_history_vec  \n",
       "0  [-0.064503215, 0.030785, -0.011886002, 0.04244...  \n",
       "1  [-0.01941134, 0.06088603, 0.030868158, 0.08166...  \n",
       "2  [-0.06357059, 0.08505998, 0.014782547, 0.10764...  \n",
       "3  [-0.057040103, 0.097636074, 0.01949272, 0.1096...  \n",
       "4  [-0.0597505, 0.10566376, 0.018543258, 0.104555...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['chat_history_vec'] = df_val['chat_history_segs'].progress_map(sentence_vec)\n",
    "df_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "778d621a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 200)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(df_train['chat_history_vec'][0], axis=1).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6007e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38054, 200), (25277, 200), (6563, 200))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_vecs = np.stack(knowledge_graph['knowledge_vec'].values)\n",
    "train_vecs = np.stack(df_train['chat_history_vec'].values)\n",
    "val_vecs = np.stack(df_val['chat_history_vec'].values)\n",
    "knowledge_vecs.shape, train_vecs.shape, val_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c0e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "train_cos = cosine_similarity(train_vecs, knowledge_vecs)\n",
    "# train_dist2 = euclidean_distances(train_vecs, knowledge_vecs)\n",
    "train_pred_index = np.argmax(train_cos, axis=1)\n",
    "df_train['predicted_knowledge_index'] = train_pred_index.tolist()\n",
    "train_acc = len(df_train[df_train['knowledge_index'] == df_train['predicted_knowledge_index']])/len(df_train)\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d93a1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05683376504647265"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_cos = cosine_similarity(val_vecs, knowledge_vecs)\n",
    "val_pred_index = np.argmax(val_cos, axis=1)\n",
    "df_val['predicted_knowledge_index'] = val_pred_index.tolist()\n",
    "val_acc = len(df_val[df_val['knowledge_index'] == df_val['predicted_knowledge_index']])/len(df_val)\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dc541f",
   "metadata": {},
   "source": [
    "## NN with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4c4b340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df=None, transform=False):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.df.loc[index, 'chat_history_concat'], \\\n",
    "                torch.as_tensor(self.df.loc[index, 'knowledge_index'], dtype=torch.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "batch_size = 256\n",
    "train_subset_size = 512\n",
    "val_subset_size = 512\n",
    "train_dl = DataLoader(CustomDataset(df_train[:train_subset_size]), batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(CustomDataset(df_val[:val_subset_size]), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "adc5d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6732d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_knowledge = 512\n",
    "dim_output = len(knowledge_embds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "effe1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# model definition\n",
    "class bilinearMatching(nn.Module):\n",
    "    # define model elements\n",
    "    def __init__(self, st=True):\n",
    "        super(bilinearMatching, self).__init__()\n",
    "        self.st = st # if using sentence transformer\n",
    "        if self.st:\n",
    "            self.encoder = SentenceTransformer('distiluse-base-multilingual-cased', device=device)\n",
    "            self.dim_chat_history = 512\n",
    "        else: \n",
    "            self.tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')\n",
    "            self.encoder = AutoModel.from_pretrained('bert-base-chinese')\n",
    "            # freeze weights of embedding layer and the first 6 layers\n",
    "            modules = [self.encoder.embeddings, *self.encoder.encoder.layer[:6]]\n",
    "            for module in modules:\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = False\n",
    "            self.dim_chat_history = 768\n",
    "        \n",
    "#         self.linear = torch.nn.Linear(self.dim_chat_history, self.dim_chat_history)\n",
    "#         self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.M = torch.nn.Parameter(torch.zeros(self.dim_chat_history, dim_knowledge))\n",
    "        nn.init.xavier_normal_(self.M)\n",
    "        self.b = torch.nn.Parameter(torch.zeros(dim_output))\n",
    "        \n",
    "        self.knowledge_embds = knowledge_embds\n",
    "#         self.knowledge_embds.requires_grad = True\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "#         print(X)\n",
    "        if self.st: # sentence transformer\n",
    "            X_embds = self.encoder.encode(X, convert_to_tensor=True).to(device)\n",
    "            X_embds.requires_grad = True\n",
    "#             print(f'chat history embeddings shape = {X_embds.shape}')\n",
    "#             # compute cosine similarities\n",
    "#             out = F.normalize(X_embds) @ F.normalize(knowledge_embds).t()\n",
    "            out = torch.matmul(X_embds, torch.matmul(self.M, knowledge_embds.T)) + self.b\n",
    "        else: # Bert\n",
    "            X_tokenized = self.tokenizer(X, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#             print(f'X_tokenized input_ids shape = {X_tokenized.input_ids.shape}')\n",
    "#             print(f'X_tokenized token_type_ids shape = {X_tokenized.token_type_ids.shape}')\n",
    "#             print(f'X_tokenized attention_mask shape = {X_tokenized.attention_mask.shape}')\n",
    "            outputs = self.encoder(**X_tokenized) # convert chat history to embeddings with bert chinese\n",
    "            last_hidden_state = outputs[0]\n",
    "#             print(f'last_hidden_state shape = {last_hidden_state.shape}')\n",
    "            X_embds = last_hidden_state[:, 0]\n",
    "#             print(f'chat history embeddings shape = {X_embds.shape}')\n",
    "            out = torch.matmul(X_embds, torch.matmul(self.M, knowledge_embds.T)) + self.b\n",
    "#             print(f'Bilinear output shape = {out.shape}')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "af064d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define metric\n",
    "def accuracy(predictions, knowledge_index):\n",
    "    num_acc = 0\n",
    "    # the label with the highest energy will be our prediction    \n",
    "    _, predicted = torch.max(predictions, 1)\n",
    "#     print(f'predicted shape = {predicted.shape}')\n",
    "    num_acc += (predicted == knowledge_index).sum().item()\n",
    "#     print(f'Compare {predicted} vs.{knowledge_index}')\n",
    "    return num_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cee90b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    #initialize every epoch \n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    \n",
    "    #set the model in training phase\n",
    "    model.train()\n",
    "    \n",
    "    # enumerate mini batches\n",
    "    for i, data in enumerate(iterator):\n",
    "#         print(f'Batch {i}')\n",
    "        chat_history, knowledge_index  = data\n",
    "        knowledge_index = knowledge_index.type(torch.LongTensor)\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # compute the model output\n",
    "        yhat = model(chat_history)\n",
    "#         print(f'yhat[0][0], yhat[0][1], yhat[1][0], yhat[1][1] = {yhat[0][0], yhat[0][1], yhat[1][0], yhat[1][1]}')\n",
    "#         print(f'yhat shape = {yhat.shape}') # batch_size x output_dim\n",
    "        # calculate loss\n",
    "#         print(f'knowledge_index = {knowledge_index}') # batch_size\n",
    "        loss = criterion(yhat, knowledge_index)\n",
    "        #compute the accuracy\n",
    "        acc = accuracy(yhat, knowledge_index)  \n",
    "        # credit assignment\n",
    "        loss.backward()\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "#         for name, param in model_matching.named_parameters():\n",
    "#             if param.requires_grad:\n",
    "#                 print(name, param.data)\n",
    "        #loss and accuracy\n",
    "        epoch_loss += loss.item()  \n",
    "        epoch_correct += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_correct / train_subset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "de172873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    #initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "\n",
    "    #deactivating dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    #deactivates autograd\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        # enumerate mini batches\n",
    "        for i, data in enumerate(iterator):\n",
    "            chat_history, knowledge_index  = data\n",
    "            knowledge_index = knowledge_index.type(torch.LongTensor)\n",
    "            # compute the model output\n",
    "            yhat = model(chat_history)\n",
    "            #compute loss and accuracy\n",
    "            loss = criterion(yhat, knowledge_index)\n",
    "            acc = accuracy(yhat, knowledge_index)\n",
    "            #loss and correct predicitions\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_correct += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_correct / val_subset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "06bec15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_matching = bilinearMatching()\n",
    "# define the optimization\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_matching.parameters(), lr=0.5, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "    train_loss, train_acc = train(model_matching, train_dl, optimizer, criterion)\n",
    "    \n",
    "    #evaluate the model\n",
    "    valid_loss, valid_acc = evaluate(model_matching, val_dl, criterion)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_matching.state_dict(), 'model_matching_weights.pt')\n",
    "    \n",
    "    print(f'Epoch {epoch}\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%\\tVal. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5441f",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b74655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (inputs, targets) in enumerate(test_dl):\n",
    "#     # evaluate the model on the test set\n",
    "#     yhat = model_matching(inputs)\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a7f90",
   "metadata": {},
   "source": [
    "## Retrieval with Lucene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# construct json file of knowledge graph\n",
    "with open('kg/knowledge_graph.jsonl', 'w', encoding='utf-8') as outfile:\n",
    "    for row in knowledge_graph.itertuples():\n",
    "        kg_dict = {}\n",
    "        kg_dict['id'] = row.Index\n",
    "        kg_dict['contents'] = row.knowledge # TODO: handle exception when knowledge = NaN (index=29026)\n",
    "        json.dump(kg_dict, outfile, ensure_ascii=False)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f570347",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pyserini.index.lucene \\\n",
    "  --collection JsonCollection \\\n",
    "  --input kg \\\n",
    "  --language zh \\\n",
    "  --index indexes/kg \\\n",
    "  --generator DefaultLuceneDocumentGenerator \\\n",
    "  --threads 1 \\\n",
    "  --storePositions --storeDocvectors --storeRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e808eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher\n",
    "\n",
    "searcher = LuceneSearcher('indexes/kg')\n",
    "searcher.set_language('zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4960aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_knowledge_graph(query):\n",
    "    hits = searcher.search(query)\n",
    "    return int(hits[0].docid)\n",
    "\n",
    "train_df['predicted_knowledge_index'] = train_df['chat_history_concat'].map(match_knowledge_graph)\n",
    "train_acc = len(train_df[train_df['predicted_knowledge_index'] == train_df['knowledge_index']])/len(train_df)\n",
    "train_acc # 0.3867151956323931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ea781",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['predicted_knowledge_index'] = val_df['chat_history_concat'].map(match_knowledge_graph)\n",
    "val_acc = len(val_df[val_df['predicted_knowledge_index'] == val_df['knowledge_index']])/len(val_df)\n",
    "val_acc # 0.3893036721011732"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9697e8a",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6039531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Vectorizer to train set [[1 0 1 0]\n",
      " [0 1 0 1]]\n",
      "Transform Vectorizer to test set [[0 1 1 1]]\n",
      "[[0.70710678 0.         0.70710678 0.        ]\n",
      " [0.         0.70710678 0.         0.70710678]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.57735027, 0.57735027, 0.57735027]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_set = [\"The sky is blue.\", \"The sun is bright.\"] #Documents\n",
    "# test_set = [\"The sun in the sky is bright.\"] #Query\n",
    "# stopWords = stopwords.words('english')\n",
    "\n",
    "# vectorizer = CountVectorizer(stop_words = stopWords)\n",
    "# transformer = TfidfTransformer()\n",
    "\n",
    "# trainVectorizerArray = vectorizer.fit_transform(train_set).toarray()\n",
    "# testVectorizerArray = vectorizer.transform(test_set).toarray()\n",
    "# print('Fit Vectorizer to train set', trainVectorizerArray)\n",
    "# print('Transform Vectorizer to test set', testVectorizerArray)\n",
    "\n",
    "# transformer.fit(trainVectorizerArray)\n",
    "# print(transformer.transform(trainVectorizerArray).toarray())\n",
    "\n",
    "# transformer.fit(testVectorizerArray)\n",
    "\n",
    "# tfidf = transformer.transform(testVectorizerArray)\n",
    "# print(tfidf.todense())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
